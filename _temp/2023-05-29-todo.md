---
layout: post
title: "todo"
categories: mathmetics
---

같은 코드를 여러 주체가 실행

backpress control

기능 특화별 분류

상태 의존성

io multiplex

linux aio vs epoll

https://stackoverflow.com/questions/5844955/whats-the-difference-between-event-driven-and-asynchronous-between-epoll-and-a


bundle exec jekyll serve



소켓이 끊긴게 아니라 

처리가 지연된거고 상대는 끊겼다고 생각해서 다시 보내면?

1. l,r로 제약을 뒀는데 fov는 안그러네?
2. 그럼 fov에선 l,r 제약이 없어?


1. 1/tan(fov/2) 
2. -w < Xe/tan(fov/2)  < w
3. l≤Xproj≤r
4. fov/2 == 45 == 1
5. 3번도 어떤 w가 들어와도 만족하는 식을 구했어
6. 2번도 그렇다면?
7. 1/tan(fov/2) 자체가 동차좌표계 변환식이다.
8. -1 < (Xe/tan(fov/2)) / we < 1
9. -1 < Xe / we < 1 
10. -w < n / r < w
11. -w < 1/(ops/adj) < w
12. -w < adj / ops < 1
13. (150+100)/50 = 5
14. 150/100 = 1.5


vectored I/O


https://learn.microsoft.com/en-us/archive/msdn-magazine/2014/june/directx-factor-the-canvas-and-the-camera

https://stackoverflow.com/questions/47593690/projected-decal-shader-using-forward-rendering-in-opengl-es

https://stackoverflow.com/questions/24944933/screen-position-unprojection-without-w

https://blog.popekim.com/en/

1. VectexX/VertexZ*CameraDepth
2. 1번식은 틀린 점이 없나? 맞다고 가정해 보자.
3. 여기서 모르는 값은 단 한개도 없다.
4. 논리적으로 연결이 안 될 뿐이다.
5. CameraDepth 보다 VertexZ 가 작다면 같은 값보다 큰 값이 될것이다.
6. 5번에 의해 CameraDepth와 VertexZ의 차이가 거의 없는 VectexX만 선택 된다.
7. 즉 바닥에 딱 붙은 투영 된 점들만이 선택 된다.


early z pass

https://martindevans.me/game-development/2015/02/27/Drawing-Stuff-On-Other-Stuff-With-Deferred-Screenspace-Decals/

https://mtnphil.wordpress.com/2014/05/24/decals-deferred-rendering/

https://www.patreon.com/posts/eksperimenty-s-69992522
https://samdriver.xyz/article/decal-render-intro

메인 카메라 선택 + ctrl + shift + f
https://gmls.tistory.com/116


https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@10.5/manual/writing-shaders-urp-reconstruct-world-position.html

https://blog.naver.com/mnpshino/221844164319


유니티 스키닝 쉐이더?

https://www.khronos.org/opengl/wiki/Compute_eye_space_from_window_space

왜 1/w

https://stackoverflow.com/questions/10389040/what-does-the-1-w-coordinate-stand-for-in-gl-fragcoord


https://www.gamedev.net/blogs/entry/1848486-understanding-half-pixel-and-half-texel-offsets/

그럼 어떤 메시를 그릴때 pixel로 넘어온 pos는 화면 좌표일땐데
-1, 1 로 어떻게 화면으로 변환하지?

텍셀 좌표계와 연계 된 질문

왜냐면 자꾸 clip 좌표와 텍셀 좌표를 연계시킴


-1, 1 이 view port min, max 이다.


https://learn.microsoft.com/en-us/windows/win32/direct3d9/directly-mapping-texels-to-pixels


"get world position from clip"

https://docs.unity3d.com/Manual/SL-PlatformDifferences.html

https://feepingcreature.github.io/math.html

clip -> ndc

ndc -> clip 

clip -> view


https://andrewhungblog.wordpress.com/2018/06/23/implementing-fog-of-war-in-unity/



1. 큐에 쌓고 하나씩 빼서 애니메이션 트리거링 한다.
2. 애니메이션이 실행 된다.
3. 애미메이터 상태가 변경되면서 물린 상태 코드가 호출 된다.




1. 사원수
2. 오일러 공식
3. 복소수
4. 테일러 전개

복소수 

사원수 -> 복소수 -> 오일러 공식 -> 테일러 급수 -> 초월 함수 ?


https://en.wikipedia.org/wiki/Reactor_pattern


스트레칭은 아플때까지 근력 운동은 안아프게..


unreal animation graph 처럼 unity는 ik 연산을 할 수 없나?

bone transform

역행렬

https://www.inf.ed.ac.uk/teaching/courses/cg/lectures/cg3_2013.pdf


https://forum.unity.com/threads/some-explanations-on-bindposes.86185/


https://moddb.fandom.com/wiki/OpenGL:Tutorials:Basic_Bones_System
유니티에서 본 웨이트 계산이 숨겨져있다고 말하는 글

https://forum.unity.com/threads/how-to-access-the-bone-positions-used-for-skinning-in-a-vertex-or-fragment-shader.1159070/

https://forum.unity.com/threads/get-skinned-vertices-in-real-time.15685/


모델의 월드 좌표계 본의 월드 좌표계


 https://github.com/MathNuts/SkeletalAnimation.git
https://webglfundamentals.org/webgl/lessons/webgl-skinning.html#toc

skinning 다음은 파츠


deferred render


https://stackoverflow.com/questions/1739259/how-to-use-queryperformancecounter


std::chrono::high_resolution_clock::now();


https://www.slideshare.net/leemwymw/deferred-decal

	pos = mul(_InverseMVP, pos);
	return pos.xyz / pos.w;


https://github.com/diharaw/texture-space-decals/blob/master/src/shader/decal_project_fs.glsl



메모리 변조 원리


https://learnopengl.com/Advanced-Lighting/Deferred-Shading

export MESA_GL_VERSION_OVERRIDE=3.3
git clone https://github.com/zeux/meshoptimizer.git
sudo apt install libglfw3-dev
sudo apt install libmagick++-dev
sudo apt install libglew-dev
sudo apt install mesa-utils libglu1-mesa-dev freeglut3-dev mesa-common-dev
sudo apt install libassimp-dev
sudo apt install libgl1-mesa-dev freeglut3-dev
sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys B7B3B788A8D3785C

LDFLAGS="$LDFLAGS -lglut ../Lib/libAntTweakBar.a -lX11 -L/home/astrokoo/work/ogldev/Common/3rdparty/meshoptimizer/build/debug -lmeshoptimizer"

https://skyul.tistory.com/337
http://lambda-the-ultimate.org/


https://en.wikipedia.org/wiki/Bidirectional_reflectance_distribution_function


https://sgvr.kaist.ac.kr/~sungeui/CG_S17/Slides/Lecture07.pdf
https://stackoverflow.com/questions/7959838/at-what-phase-in-rendering-does-clipping-occur


mask map

https://scahp.tistory.com/66



erly z pass 와 masked material 
https://forums.unrealengine.com/t/early-z-pass-performance-breakthrough/115013
https://blog.naver.com/PostList.naver?blogId=leesg213&from=postList&categoryNo=2
https://mgun.tistory.com/2298
https://forums.unrealengine.com/t/early-z-pass-performance-breakthrough/115013




KajiyaKayAnisotropic
https://forum.unity.com/threads/general-questions-regarding-early-z.1065779/

https://ypchoi.gitbooks.io/rendering-techniques/content/z_prepass.html



reinterpret_cast


https://github.com/OGRECave/ogre.git
https://forum.unity.com/threads/missing-changed-light_attenuation-macro.511767/
https://de45xmedrsdbp.cloudfront.net/Resources/files/2013SiggraphPresentationsNotes-26915738.pdf
https://learnwebgl.brown37.net/09_lights/lights_attenuation.html


https://claude.ai/chat/741ab9a2-b79a-450a-b5e1-67120f79fc05
https://nybot-house.tistory.com/51


https://stackoverflow.com/questions/31759347/why-do-we-implement-lighting-in-the-pixel-shader


https://learn.microsoft.com/en-us/windows/win32/dxtecharts/common-techniques-to-improve-shadow-depth-maps?redirectedfrom=MSDN


https://blog.naver.com/zxwnstn/223297902618
https://gamedev.stackexchange.com/questions/205025/how-to-execute-early-depth-test
https://www.gamedev.net/forums/topic/622047-early-z/
https://chulin28ho.tistory.com/777
https://interplayoflight.wordpress.com/2017/10/25/how-unreal-renders-a-frame/
https://ypchoi.gitbooks.io/rendering-techniques/content/z_prepass.html

z-prepass는 거리기반 소트를 쉽게 할 수 없는 밀도가 높은(역주 : 메시 내의 버택스들을 소팅할 수 없기 때문에 오버드로우 관리를 소팅으로 해결 못함) 나뭇잎 같은 지오메트리의 경우 특히 오버드로우를 줄이는데 도움을 줍니다.


early z 실행 조건이 다음과 같을때 

1. 바인딩된 FS 에서 z값을 조작하지 않을것 (굳이 언리얼을 끼언자면 PDO - pixel depth offset 가 대표적)

2. 바인딩된 FS 에서 discard 표현식이 없을것(비록 조건절 내부에 있더라도)

3. 뎁스 쓰기와 알파테스트가 활성화 되지 않을것

3번이라면 gpu가 정말로 안쓸려고 비활성화 한 경우와 early z 를 위해 쓰기를 활성화 한 경우를 어떻게 구분하지?

https://community.khronos.org/t/early-z-and-discard/74748/6

the sampled demonstrates two ways to take advantage of early z rejection:
front to back rendering and z prepass. with a z prepass the first pass populates the Z buffer with depth values from all opaque geometry.

a null pixel shader is used, and the color buffer is not updated.

for the second pass, the geometry is resubmitted with Z writes disabled but Z testing on, and full vertex and pixel shading is performed.


https://developer.arm.com/documentation/102224/0200/Early-Z
discard(), gl_FragDepth, Alpha-to-coverage



read lock, write lock

read concurrency, write concurrency




read가 많은 cache 설정 시 장점

read thread 개수가 많고 write thread 는 최소

read 를 동시에 많이 할 수 있고 write 요청 처리시 모든 read 요청 block





https://stackoverflow.com/questions/4531508/c-opengl-z-buffer-prepass


tone mapping


https://www.infoq.com/news/2014/10/cpp-lock-free-programming/

어셈블리에서 함수 리턴 값은 레지스터에 저장? 큰 값은 어떻게?

struct A
{
        char a[100000000];
};


A Foo()
{
        return A();
}

int main()
{
        A a = Foo();
        return 0;
}

https://www.youtube.com/watch?v=fbYknr-HPYE

걱정할 필요가 없다.
데이터가 살아 있는지 확인할 필요가 없다.


making sure we keep it intact making sure we copy it

we can simply steal the resources that might be attached

to that specific object and them somewhere else because

we know that it's temporary it's not going to exist for very long where if you take in something like this then

you can't i mean apart from the fact that is's cost you

can't really steal anything from this name string

because it might be used in a number of factions whereas this is clearly something that is temporary only going to be used with this particular call of print name and that's where the power really comes from so remember L values are baically variables that have some kind of storage back in them our values 


https://www.youtube.com/watch?v=80TXwV_sdCY
https://www.linkedin.com/pulse/c-return-value-optimization-dipanjan-das-roy/
https://learn.microsoft.com/en-us/cpp/cpp/temporary-objects?view=msvc-170




unfortunately x lives right here i didnot control 


https://nanze.tistory.com/entry/Cpp-Universal-reference-Reference-Collapsing-Rules

unique_ptr과 std::move


https://velog.io/@kodskm/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98-%EA%B2%BD%EC%9A%B0%EC%9D%98-%EC%88%98-%EA%B0%9C%EB%85%90


https://solved.ac/
https://github.com/codeisneverodd/programmers-coding-test




명시적으로 constructor를 호출해야 함
make_unique는 가능함


https://github.com/daancode/a-star

https://www.youtube.com/watch?v=atTzqxbt4DM&list=PLi-xJrVzQaxXC2Aausv_6mlOZZ2g2J6YB&index=4


https://github.com/ChangguHan/codingtestbasic/blob/master/BJ15649.py


https://www.acmicpc.net/problem/1753

```c++
#include <iostream>
#include <vector>
using namespace std;

int N, M;
vector<int> rs;
vector<bool> chk;

void recur(int num) {
    if (num == M) {
        for (int i = 0; i < M; ++i) {
            cout << rs[i] << " ";
        }
        cout << endl;
        return;
    }
    for (int i = 1; i <= N; ++i) {
        if (!chk[i]) {
            chk[i] = true;
            rs.push_back(i);
            recur(num + 1);
            chk[i] = false;
            rs.pop_back();
        }
    }
}

int main() {
    cin >> N >> M;
    chk.resize(N + 1, false);
    recur(0);
    return 0;
}


https://ansohxxn.github.io/algorithm/ahocorasick/


git index
https://johngrib.github.io/wiki/git/index/
checkout 

주사위 눈이 아래와 같을 때 
1 2 3 4 5 6
더해서 30 이 되는 모든 경우의 수


recursion

	for i = 0 ~ n

		if i == 30
			exit

		recursion i + 1



int main() {

	vector<int> dise = {1, 2, 3, 4, 5, 6};

	for (int i = 0; i < dise.size(); i++) {
		for (int j = 0; j < dise.size(); j++) {
			cout << dise[i] << "," << dise[j] << endl;
		}
	}

	// 여러번 굴리기
	for (int i = 0; i < dise.size(); i++) {
	}
	for (int j = 0; j < dise.size(); j++) {
	}
	for (int k = 0; k < dise.size(); k++) {
	}

	function<void(int)> run;
	int runCount = 0;
	int	playLimit = 10;
		
	// n 번 굴리기
	run = [&run, &playLimit](int runCount) -> void {

		if (runCount == playLimit) {
			return;
		}
		run(++runCount);
	};
	run(runCount);

	// dfs는 base 자료 구조가 2차원. MxN 좌표 

	return 0;
}        


https://github.com/da-in/tech-interview-study/tree/main

자리까지 맞는 데이터간 비교를 통해  정확한 문자를 찾는다.


using namespace std;

//vector<int> dise = { 1,2,3,4,5,6 };
//int diceCnt = 6;
//int boardCnt = 4;

//vector<int> dise = { 2, 5 };
//int diceCnt = 2;
//int boardCnt = 10;

vector<int> dise = { 1,2,3,4,5,6 };
int diceCnt = 6;
int boardCnt = 30;

int sum;
int result;
vector<int> valueToIndex;
int bigDice;
vector<int> progress;
vector<int> failed;

int g;
int p;

struct ScopeTime
{
    ScopeTime(const char* InScopeMessage)
    {
        start = std::chrono::high_resolution_clock::now();
        MessageString = InScopeMessage;
    }

    ~ScopeTime()
    {
        auto end = chrono::high_resolution_clock::now();
        chrono::duration<double> elapsed_seconds = end - start;
        cout << MessageString << " : " << elapsed_seconds.count() * 1000 << " msec" << endl;
    }

    chrono::time_point<std::chrono::high_resolution_clock> start;
    const char* MessageString;
};

void calculate(int index)
{
    for (int i = index; 0 <= i; i--) {
        auto val = dise[i];
        auto need = boardCnt - (sum + val);

        if (need < 0) {
            continue;
        } 
        else if (need == 0) {
            result++;
            continue;
        }
        else {
            index = valueToIndex[need];
            sum += val;
            calculate(index);
            sum -= val;
        }
    }
}

int main() {
   /* Enter your code here. Read input from STDIN. Print output to STDOUT */

    std::sort(dise.begin(), dise.end());

    auto s = dise.size() - 1;

    bigDice = dise[s];
    valueToIndex.resize(30, s);
    valueToIndex[bigDice] = s;

    for (int i = dise.size() - 1; 0 <= i; i--) {
        auto value = dise[i];
        valueToIndex[value] = i;
    }

    for (int i = bigDice - 1; 0 <= i; i--) {
        auto index = valueToIndex[i];
        if (index < 0) {
            valueToIndex[i] = s;
        }
        else {
            s = index;
        }
    }

    {
        diceCnt -= 1;
        ScopeTime checkTime("calculate");
        calculate(diceCnt);
    }

    cout << result;
    return 0;
}



1. 캐릭터당 draw call 개수
2. signed distance (https://scahp.tistory.com/17)
3. kd 알고 (https://www.baeldung.com/cs/k-d-trees) or r tree
4. str 알고
5. Terrain Layers
6. mono time steady time
7. covolution (확률 함수/적분/계수/확률이산분포)
8. marshal
9. pbr vs none pbr
10. string 과 stream
11. make_shared를 사용하는 이유, 순환 참조
12. bcs class 구조 (어떤 생각으로 짰는지, iocp zero copy)
13. terrain rendering (https://www.reddit.com/r/GraphicsProgramming/comments/13i55ae/whats_the_stateoftheart_terrain_rendering/)
14. array segment (https://velog.io/@yarogono/C-ArraySegment%EB%9E%80) c++에서 같은 기능을 하는 클래스는 없나요? C++에서는 포인터 사용으로 부분 접근이 가능합니다. (배열에서 특정 부분을 따로 때낼수가 없다는 거구나)
15. shadow (https://illu.tistory.com/1253)
16. shadow mask (https://catlikecoding.com/unity/tutorials/custom-srp/shadow-masks/)
17. pixel to world when (https://stackoverflow.com/questions/13419605/how-to-map-x-y-pixel-to-world-cordinates)
18. unity rendering (https://junbastick.tistory.com/6)
19. hdr (https://docs.unity3d.com/560/Documentation/Manual/HDR.html)
20. tone mapping (https://forum.unity.com/threads/texture-creation-workflow-for-tonemapping.1343789/) / 실제로 hdr 에서 tonemap 하기전까지 밝아야하는게 아닌지... 그런 셈풀이 있는지
21. gamma space (https://blog.naver.com/PostView.nhn?blogId=cdw0424&logNo=221827528747)
22. bloom (영향 받고 싶지 않은 픽셀은?/https://junbastick.tistory.com/67?category=1008778)
23. FragmentCommonData 이거 확인
24. srgb (https://unlimited3d.wordpress.com/2020/01/08/srgb-color-space-in-opengl/)
25. simd & shader if statement (https://jahej.com/alt/2011_04_06_if-simd-o_o-or-how-to-vectorize-code-with-different-execution-paths-2.html)
- lerp(x, y, step(a, b))
26. character 조립 확실히
27. vec3(0.2126f, 0.7152f, 0.0722f) Luminance Coefficients
28. resourcebundle이 되어 다른 asset의 폴더를 가져감
- resourcebundle은 몬스터 A, 몬스터 B 같은 조립 정보 그외 asset/character는 실제 리소스
29. c# marshal (https://hwanine.github.io/network/Marshalling/)
30. GGX PBS Schick Fresnel (https://lifeisforu.tistory.com/500; https://blog.naver.com/canny708/221551990444)
31. bind pose (https://help.autodesk.com/view/MAYAUL/2022/ENU/?guid=GUID-36808BCC-ACF9-4A9E-B0D8-B8F509FEC0D5)

quick cpu
https://coderbag.com/product/quickcpu

https://docs.unity3d.com/Manual/LinearRendering-LinearOrGammaWorkflow.html
https://forum.unity.com/threads/question-about-gamma-and-linear-work-flow-in-unity.1147007/

왜 light 타입별로 나눴는가? 같이 쓸땐 어떻게 할건가?
그림자는 개별 물체를 그릴때 같이 그리지 않는가?

vertShadowCaster/fragShadowCaster는 조명 공통 사용
네 맞습니다. 기본적으로 vertShadowCaster, fragShadowCaster 같은 그림자 렌더링 쉐이더 코드 자체는 조명 유형에 상관없이 공통으로 사용됩니다. 조명 유형별로 다른 부분은 주로 뷰-프로젝션 변환 매트릭스가 됩니다.

Direction Light(방향성 조명)
한 방향에서만 그림자를 렌더링하므로 단일 뷰-프로젝션 매트릭스 사용
Point Light(점 조명)
6개의 축을 가리키는 6개의 다른 뷰-프로젝션 매트릭스로 렌더링
Spot Light(스폿라이트)
스폿라이트 위치, 방향, 원뿔 각도를 반영한 특별한 뷰-프로젝션 매트릭스 생성
즉, 실제 vertShadowCaster/fragShadowCaster 쉐이더 코드가 호출되기 전에 Unity 렌더링 파이프라인 내에서 해당 조명 유형에 맞는 적절한 변환 매트릭스가 계산되고 바인딩 됩니다.

그리고 이 매트릭스를 사용해 vertShadowCaster에서 버텍스 위치 변환, fragShadowCaster에서 투영 등의 작업을 수행하게 됩니다.

따라서 쉐이더 코드 자체는 조명 유형 독립적이지만, 렌더러 파이프라인에서는 조명 종류에 따라 다른 변환 매트릭스를 사용하여 렌더링하는 방식입니다.

tier setting
build in shader setting
    -> custom? (https://forum.unity.com/threads/custom-shader-doesnt-fill-depth-and-normals-for-post-processing.1156454/)
baked shadow 


https://panoskarabelas.com/posts/screen_space_shadows/
https://forum.unity.com/threads/what-are-screen-space-shadows.1363755/

ShadeSHPerPixel

y = ax + b

y = (b-a)x + a

https://www.geeksforgeeks.org/problems/median-in-a-row-wise-sorted-matrix1527/0

https://bytewrangler.blogspot.com/2011/10/signed-distance-fields.html
https://linkmemo.tistory.com/category/C%2B%2B%20%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D
https://stackoverflow.com/questions/2321511/what-is-meant-by-resource-acquisition-is-initialization-raii


https://stackoverflow.com/questions/20895648/difference-in-make-shared-and-normal-shared-ptr-in-c



unity_ShadowMask 와 _ShadowMapTexture 의 차이는??

https://www.geeksforgeeks.org/find-median-row-wise-sorted-matrix/


half3 ShadeSHPerPixel (half3 normal, half3 ambient, float3 worldPos)
{
    half3 ambient_contrib = 0.0;

    #if UNITY_SAMPLE_FULL_SH_PER_PIXEL
        // Completely per-pixel
        #if UNITY_LIGHT_PROBE_PROXY_VOLUME
            if (unity_ProbeVolumeParams.x == 1.0)
                ambient_contrib = SHEvalLinearL0L1_SampleProbeVolume(half4(normal, 1.0), worldPos);
            else
                ambient_contrib = SHEvalLinearL0L1(half4(normal, 1.0));
        #else
            ambient_contrib = SHEvalLinearL0L1(half4(normal, 1.0));
        #endif

            ambient_contrib += SHEvalLinearL2(half4(normal, 1.0));

            ambient += max(half3(0, 0, 0), ambient_contrib);

        #ifdef UNITY_COLORSPACE_GAMMA
            ambient = LinearToGammaSpace(ambient);
        #endif
    #elif (SHADER_TARGET < 30) || UNITY_STANDARD_SIMPLE
        // Completely per-vertex
        // nothing to do here. Gamma conversion on ambient from SH takes place in the vertex shader, see ShadeSHPerVertex.
    #else
        // L2 per-vertex, L0..L1 & gamma-correction per-pixel
        // Ambient in this case is expected to be always Linear, see ShadeSHPerVertex()
        #if UNITY_LIGHT_PROBE_PROXY_VOLUME
            if (unity_ProbeVolumeParams.x == 1.0)
                ambient_contrib = SHEvalLinearL0L1_SampleProbeVolume (half4(normal, 1.0), worldPos);
            else
                ambient_contrib = SHEvalLinearL0L1 (half4(normal, 1.0));
        #else
            ambient_contrib = SHEvalLinearL0L1 (half4(normal, 1.0));
        #endif

        ambient = max(half3(0, 0, 0), ambient+ambient_contrib);     // include L2 contribution in vertex shader before clamp.
        #ifdef UNITY_COLORSPACE_GAMMA
            ambient = LinearToGammaSpace (ambient);
        #endif
    #endif

    return ambient;
}





우리가 보는 이미지도 마찬가지인데 어두운 곳과 밝은 곳의 차이를

사람이 효과적으로 인지하기 위해 입력 색상 값을 제곱근에 비례하게 왜곡시켜 보여주도록

gamma space란걸 모니터 제조사에서 만들어 이미지를 출력해준다.

gamma space란 입력 x (0.0 ~ 1.0) 값을 y = x^2.2 로 맵핑해주는 것으로 

아래의 그래프와 같고 


gamma space 를 gray scale 이미지에 적용해보면 사람이 보기에 믿믿한 위쪽의 색상 변화량이 

아래쪽 이미지로 좀 더 인지하게 쉽게 변한 걸 확인 할 수 있다.


sRGB

애초에 gamma space는 흑백 CRT에서 출발했는데 칼라 모니터가 나오면서 칼라 이미지가 

gamma space로 인해 전체적으로 어두워지는 현상이 발생하게 된다.


그래서 생겨난게 sRGB로 원본 이미지를 일부러 밝게 저장하여 gamma space로 변환 될때

원본 이미지로 출력 되도록 복원 시키는 방법이 생겨났고 이를 gamma correction이라고 한다.

gamma correction을 통해 원본 이미지로 복원시키는 방법이 생겨났다.



	fixed4 FragBloom(VaryingsDefault i) : SV_Target
	{
		half4 color = SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.texcoord);
		return color;
		
		//color.rgb = tonemap_uc2(color.rgb);

		//  // reinhard tone mapping
		//  half3 mapped = color / (color + half3(1.0, 1.0, 1.0));
		//  // gamma correction 
		//  mapped = pow(mapped, half(1.0) / 2.2);
		//  color = half4(mapped, color.a);	
		// return color;

		half3 bloom = SAMPLE_TEXTURE2D(_Bloom_Result, sampler_Bloom_Result, i.texcoord).rgb *
			ONE_MINUS_THRESHHOLD_TIMES_INTENSITY;
		color.rgb += bloom;

		#if UNITY_COLORSPACE_GAMMA
			color.rgb = clamp(color.rgb, 0, 4);
			color.rgb = GammaToLinearSpace(color.rgb);
		#endif

		color.rgb = tonemap_uc2(color.rgb);
		color.rgb = (color.rgb - 0.5h) * CONTRAST + 0.5h;

		color.rgb *= _RemapColor.rgb;

		fixed lum = Luminance(color.rgb);
		color.rgb = lerp(fixed3(lum, lum, lum), color.rgb, SATURATION);

		//#if UNITY_COLORSPACE_GAMMA
		//color.rgb = LinearToGammaSpace(color.rgb);;
		//#endif

		return color;
	}



    gamma space 변환은 디스플레이 장치에서 처리되는데 입력 값 x에 대한 출력 y는 보통

다음의 공식을 따른다.

\\( y = x^2.2 \\)

한편, 컴퓨터에서 색상은 숫자로 표현되는데 rgb 각각은 0.0 에서 1.0의 범위를 가진다.

> <font size="2"> 
> 고해상도 HDR 모니터를 사용한다면 0.0 ~ 1.0 범위를 넘어 표현할 수 있다.
> </font>

https://learn.microsoft.com/en-us/windows/win32/direct3d11/d3d10-graphics-programming-guide-output-merger-stage

When you use sRGB render targets, the runtime converts the render target color into linear space before it performs blending. The runtime converts the final blended value back into sRGB space before it saves the value back to the render target.

텍스처가 srgb란건 그래픽 api가 자동으로 셈플링 할때

linear라 바꿔준다는 말

그래서 이미 srgb 작업 환경에서 밝아진 데이터를 가지고 blend 

하는 걸 방지


한편, 컴퓨터에서 색상은 숫자로 표현되는데 rgb 각각은 0.0 에서 1.0의 범위를 가진다.

> <font size="2"> 
> HDR 환경에선 1.0의 범위를 훨씬 띄어넘는 수를 사용한다.
> </font>


player setting의 color space는 framebuffer의 srbg이냐
아니냐를 지정하고
텍스쳐의 srgb 설정은 텍스처 작업 환경이 srgb이냐를 지정

사실 작업 환경이 HDR이라도 TGA, PNG로 저장했다면 srgb임

그러니깐 어떤 아웃풋을 낼건지 먼저 정하는게 우선

그에 맞춰 작업하면 됨


그럼 gamma space 일경우 output merge에서 blend 할때 linear 로 바꿔 블랜드하고 다시 srbg로 변환하는데 linear의 경우 frame buffer가 이미 linear 환경이라 linear로의 변환이 필요 없고 그래서 다시 srbg로 원복의 과정도 필요 없음


srgb 로 지정된 텍스처의 경우 감마 보정이 되어 셈플링 되어

linear 값이 되는데 그 값을 그대로 감마 프레임 버퍼에 보내면

다시 감마 적용 -> 블랜드 -> 원복 이래서 문제가 되겠어?


sRGB는 역 감마라고 볼 수 있는데

따라서 linear환경에선 그래도 출력하면 모니터가 알아서 

감마 처리해서 문제 없음



gamma space 변환은 모니터 장치에서 실행 되며 


> <font size="2"> 
> 빛을 높은 해상도로 표현하기 위한 HDR 환경에선 색상은 1.0 범위를 넘어 표현할 수 있다.
> 다만, gamma space에선 HDR도 최종 출력 전엔 1.0의 범위로 변환되어 출력한다.
> </font>




1.감마는 모니터에서 실행
2.감마 환경에서 작업한 srgb는 2.2 임
3.유니티 감마 칼라 스페이스는 아무것도 안함
4.유니티 선형 칼라 스페이스에선 텍스처 셈플링시 srgb를 자동 선형화
5.유니티 선형 칼라 스페이스에선 쉐이더 출력 값을 srgb로 자동 변환
6.만약 HDR 모드이면 쉐이더 출력 값 srgb로 변환 안함


https://www.slideshare.net/slideshow/color-space-gamma-correction/124547827
https://rito15.github.io/posts/unity-srgb-linear-gamma-color-space/
https://www.youtube.com/watch?v=9g-4aJhCnyY

1.유저가 감마 환경에서 그레이 스케일을 그린다.

## Gamma, These Days 

사실 요즘에는 3D 엔진에서 Graphic API를 활용해 감마를 자동으로 보정해줘 사용자 입장에선 

크게 신경 쓸 부분은 없다.

